"""
This module defines the FastAPI endpoints for the Gen AI project, handling 
requests related to question answering, feedback, and conversational state resets.
"""

from fastapi import FastAPI

from gen_ai.deploy.model import ItemInput, LLMOutput, ResetInput, ResetOutput, ResponseInput, ResponseOutput
from gen_ai.llm import respond_api

app = FastAPI()

items_db = {}


@app.post("/respond/", response_model=LLMOutput)
def respond(query: ItemInput) -> LLMOutput:
    """
    Handles a POST request to the '/respond/' endpoint, processing the given query
    through a conversational model and generating a structured response.

    This function takes a query input, sends it to the respond_api for processing,
    and then formats the response into a structured LLMOutput object. It is part of
    a FastAPI application and is designed to work with asynchronous conversation models
    or chatbots.

    Args:
        query (ItemInput): An object containing the user's query and context for the
                           conversation. This object must have two attributes: `question`,
                           which is a string representing the user's query, and `member_context_full`,
                           which provides additional context necessary for generating a response.

    Returns:
        LLMOutput: An object containing the structured response from the conversational model.
                   This includes the round number, the latest answer generated by the model,
                   and placeholders for additional fields such as `response_id`,
                   `plan_and_summaries`, `additional_information_to_retrieve`, `context_used`,
                   `urls_to_kc`, and `sections_to_b360`. Most of these fields are initialized
                   with empty strings or arrays as placeholders.

    Raises:
        This function itself does not explicitly raise any exceptions but relies on the
        `respond_api` function's behavior. If `respond_api` encounters issues or if the input
        does not meet expected formats, the caller should handle potential exceptions
        according to the implementation of `respond_api`.

    Note:
        - The `LLMOutput` and `ItemInput` types should be properly defined elsewhere in the codebase,
          including their fields and types.
        - The actual implementation of `respond_api` is not shown here and must be implemented
          or imported from another module. This function's behavior, especially error handling,
          will depend on the `respond_api` implementation.
    """
    conversation = respond_api(query.question, query.member_context_full)
    response = LLMOutput(
        round_number=str(conversation.round_numder),
        answer=conversation.exchanges[-1].answer,
        response_id="",
        plan_and_summaries="",
        additional_information_to_retrieve="",
        context_used=conversation.exchanges[-1].relevant_context,
        urls_to_kc=conversation.exchanges[-1].urls,
        attributes_to_b360=conversation.exchanges[-1].attributes_to_b360,
        attributes_to_kc_km=conversation.exchanges[-1].attributes_to_kc_km,
        attributes_to_kc_mp=conversation.exchanges[-1].attributes_to_kc_mp,
        confidence_score=str(conversation.exchanges[-1].confidence_score),
        session_id=conversation.session_id,
    )

    return response


@app.post("/feedback/", response_model=ResponseOutput)
def feedback(query: ResponseInput) -> ResponseOutput:
    """Submits feedback using the object ResponseInput
    Returns: ResponseOutput
    """
    _ = query
    response = ResponseOutput(success=True, response_id="123")

    return response


@app.post("/reset/", response_model=ResetOutput)
def reset(query: ResetInput) -> ResponseOutput:
    """Resets the state using the object ResetInput
    Returns: ResetOutput
    """
    _ = query
    response = ResetOutput(success=True)

    return response


@app.get("/health")
def health_check():
    """Provides a health pulse for Cloud Deployment"""
    return {"status": "ok"}
